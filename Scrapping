#!/usr/bin/env python3
import urllib
from urllib import request
from urllib.parse import quote
from bs4 import BeautifulSoup
from collections import Counter
import os 

###Get the HTML of a page
target_page="https://www.imdb.com/title/tt0118480/reviews?ref_=tt_ql_3"
resp = urllib.request.urlopen(target_page)
soup = BeautifulSoup(resp, 'html.parser')

###Create an empty list
list_1=[]

###Put all the links in a page in a list
for link in soup.find_all('a'):
    list_1.append(link.get('href'))
    
###find the comments
me = soup.find_all("div", {"class": "text show-more__control"})

###Open a documents and write the comments to it
doc = open(DESIRED_FILENAME, 'w+')
me =str(me)
doc.write(me)
doc.close()

###Open the file, read contents, count most common words
###Remeber, you need to import Counter by: from collections import Counter 
file = open("[DESIRED_FILENAME", "rt")
data=file.read()
words=data.split()
Counter = Counter(words)
Counter.most_common(10)

###Remove stop words
stop_words = set(stopwords.words('english')) 
fil = [w for w in words if not w in stop_words] 

from collections import Counter
Counter = Counter(fil)
Counter.most_common(10)
